@Article{firth:93,
  Title                    = {Bias Reduction of maximum likelihood estimates},
  Author                   = {David Firth},
  Journal                  = bio,
  Year                     = {1993},
  Number                   = {1},
  Pages                    = {27--38},
  Volume                   = {80},
}

@Article{kosmidisdot:14,
  Title                    = {Improved estimation in cumulative link models},
  Author                   = {K.},
  Journal                  = {Journal of the Royal Statistical Society, Series B: Methodological},
  Year                     = {2014},
  Number                   = {1},
  Pages                    = {169--196},
  Volume                   = {76},
  Doi                      = {10.1111/rssb.12025},
  ISSN                     = {1467-9868},
  Keywords                 = {Adjusted counts, Adjusted score equations, Ordinal response models, Reduction of bias, Shrinkage},
  Url                      = {http://dx.doi.org/10.1111/rssb.12025}
}


@Article{kosmidisdot:14b,
  Title                    = {Bias in parametric estimation: reduction and useful side-effects},
  Author                   = {K.},
  Journal                  = {Wiley Interdisciplinary Reviews: Computational Statistics},
  Year                     = {2014},
  Number                   = {3},
  Pages                    = {185--196},
  Volume                   = {6},
  Doi                      = {10.1002/wics.1296},
  ISSN                     = {1939-0068},
  Keywords                 = {jackknife/bootstrap, indirect inference, penalized likelihood, infinite estimates, separation in models with categorical responses},
  Owner                    = {yiannis},
  Publisher                = {John Wiley \& Sons, Inc.},
  Timestamp                = {2015.04.16},
  Url                      = {http://dx.doi.org/10.1002/wics.1296}
}


@Article{kosmidisdot:11,
  Title                    = {Multinomial logit bias reduction via the Poisson log-linear model},
  Author                   = {K. and Firth, David},
  Journal                  = {Biometrika},
  Year                     = {2011},
  Number                   = {3},
  Pages                    = {755-759},
  Volume                   = {98},

  Owner                    = {yiannis},
  Timestamp                = {2010.05.16}
}

@Article{kosmidisdot:10,
  Title                    = {A generic algorithm for reducing bias in parametric estimation},
  Author                   = {K. and Firth, David},
  Journal                  = {Electronic Journal of Statistics},
  Year                     = {2010},
  Pages                    = {1097--1112},
  Volume                   = {4},

  Doi                      = {10.1214/10-EJS579},
  Owner                    = {yiannis},
  Timestamp                = {2010.11.10},
  Url                      = {http://dx.doi.org/10.1214/10-EJS579}
}

@Article{kosmidisdot:09,
  Title                    = {Bias reduction in exponential family nonlinear models},
  Author                   = {K. and Firth, David},
  Journal                  = {Biometrika},
  Year                     = {2009},
  Number                   = {4},
  Pages                    = {793--804},
  Volume                   = {96},

  Abstract                 = {In Firth (1993, Biometrika) it was shown how the leading term in the asymptotic bias of the maximum likelihood estimator is removed by adjusting the score vector, and that in canonical-link generalized linear models the method is equivalent to maximizing a penalized likelihood that is easily implemented via iterative adjustment of the data. Here a more general family of bias-reducing adjustments is developed for a broad class of univariate and multivariate generalized nonlinear models. The resulting formulae for the adjusted score vector are computationally convenient, and in univariate models they directly suggest implementation through an iterative scheme of data adjustment. For generalized linear models a necessary and sufficient condition is given for the existence of a penalized likelihood interpretation of the method. An illustrative application to the Goodman row-column association model shows how the computational simplicity and statistical benefits of bias reduction extend beyond generalized linear models.},
  Doi                      = {10.1093/biomet/asp055},
  Eprint                   = {http://biomet.oxfordjournals.org/cgi/reprint/96/4/793.pdf},
  Owner                    = {yiannis},
  Timestamp                = {2015.04.16},
  Url                      = {http://biomet.oxfordjournals.org/cgi/content/abstract/96/4/793}
}
